<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>RNNPredict</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">RNNPredict</h1>
      <h2 class="project-tagline">Time-Series Sequence Generation for Recurrent Neural Networks</h2>
    </section>

    <section class="main-content">
      <p>I use this financial loss function to train my deep learning financial time-series models that downside risk is not equal to upside risk. This may seem somewhat obvious however some banks still apply a squared-error loss function on financial returns. Squared-error does not account for the sinange of the predicted return. Therefore, if you bet on a predictive model returning 1% a squared-error loss function would penalize an actual return of -1% equally as bad as a prediction of 3%. This cannot be used for training deep learning models because the actual return of 3% would have caused the investor to gain money while the actual return of -1% loses money.</p>
<p>This a Bayes loss function which accounts for the sinange of the return. This allows the deep learning model to learn when the predictive financial return is close to 0% the trading signal shall be 0 and therefore the model should take no position in the asset. (Again, a squared-error loss function cannot correctly adjust to the risks of losing money when financial predictions are too close to 0%)</p>
<p>For the very determined I also included a loss function which account for the signage of returns using Euclidean distance and shift-bias. This loss functions is more complex than Bayes</p>

  </body>
</html>
